=title Download a web page
=timestamp 2015-11-20T13:00:01
=indexes exercises, projects
=status show
=books nodejs, javascript, python, flask, ruby
=author szabgab
=archive 1
=comments_disqus_enable 0

=abstract start

Building a web crawler starts by fetching one page. It can be an HTML page. The RSS or Atom feed of a web site.
Some site provide API where get the response as a <a href="/json">JSON string</a>.

It can be downloading an image or some other binary file.

=abstract end

The task is quite simple. Given a URL fetch the thing that is behind it and put it in a variable.

For a variation on this, you can write a function that will get a URL and a filename and will save
the content it received in the given file.

<h2>Solutions</h2>

<ul>
  <li><a href="/download-a-page-using-ruby">Ruby: Download an HTML page using Ruby</a></li>
</ul>

